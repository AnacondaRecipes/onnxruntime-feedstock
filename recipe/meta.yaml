{% set name = "onnxruntime" %}
{% set version = "1.20.1" %}

package:
  name: {{ name|lower }}{{ suffix }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v{{ version }}.tar.gz
    sha256: d4c005506a2bbf88a838b14f8d1578406b8be2fb64abb50beeff908fb272529e
    patches:
      - patches/dont-call-pip-on-win.patch                                  # [win]
      # Workaround for https://github.com/conda-forge/onnxruntime-feedstock/pull/56#issuecomment-1586080419
      - patches/windows_workaround_conflict_onnxruntime_dll_system32.patch  # [win]
      - patches/0001-remove-broken-cuda-moe-test-case.patch                 # [(ep_variant == "cuda")]
      - patches/0002-skip-testing-python-iobinding.patch                    # [(ep_variant == "cuda")]
      - patches/skip_custom_op_test_with_cuda.patch                         # [(ep_variant == "cuda")]
      - patches/fix_cwd_name_on_win.patch                                   # [win]

build:
  number: 0
  skip: True  # [s390x]
  string: gpu_cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{PKG_HASH}}_{{ PKG_BUILDNUM }}  # [(ep_variant == "cuda")]
  ignore_run_exports_from:
    - zlib
  entry_points:
    - onnxruntime_test = onnxruntime.tools.onnxruntime_test:main
  missing_dso_whitelist:
    - '**/api-ms-win-core-path-l1-1-0.dll'     # [win]

requirements:
  build:
    - python
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }} # [(ep_variant == "cuda")]
    - cmake
    - git       # [not win]
    - ninja     # [not win]
    - patch     # [unix and (ep_variant == "cuda")]
    - m2-patch  # [win]
  host:
    - python
    - pip
    - wheel
    - packaging
    - python-flatbuffers
    - zlib {{ zlib }}
    - numpy 2.0  # [py<313]
    - numpy 2.1  # [py>=313]
    - pybind11 2.13
    # GPU requirements
    - cuda-nvcc {{ cuda_compiler_version }}        # [(ep_variant == "cuda")]
    - cuda-nvrtc-dev {{ cuda_compiler_version }}   # [(ep_variant == "cuda")]
    - cuda-cudart-dev {{ cuda_compiler_version }}  # [(ep_variant == "cuda")]
    # Needed for CUDA profiling.                   # [(ep_variant == "cuda")]
    - cuda-cupti-dev {{ cuda_compiler_version }}   # [(ep_variant == "cuda")]
    - cudnn 9.1.1.17*                              # [(ep_variant == "cuda")]
    - libcublas-dev                                # [(ep_variant == "cuda")]
    - libcufft-dev                                 # [(ep_variant == "cuda")]
    - libcurand-dev                                # [(ep_variant == "cuda")]
    - libcusparse-dev                              # [(ep_variant == "cuda")]
  run:
    - __cuda  # [linux and (ep_variant == "cuda")]
    - coloredlogs
    # numpy 2.0 sets the min pin to 1.19 and 2.1 sets 1.21 but upstream requires at least 1.21.6
    - numpy >=1.21.6,<3
    - packaging
    - protobuf
    - python
    - python-flatbuffers
    - sympy
  run_constrained:
    - onnxruntime <0a0  # [suffix == "-novec"]

test:
  imports:
    - onnxruntime
  commands:
    - pip check
    - onnxruntime_test --help
  requires:
    - pip

about:
  home: https://onnxruntime.ai/
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://onnxruntime.ai/docs/
  summary: cross-platform, high performance ML inferencing and training accelerator
  description: |
    ONNX Runtime is a cross-platform machine-learning model accelerator,
    with a flexible interface to integrate hardware-specific libraries.
    ONNX Runtime can be used with models from PyTorch, Tensorflow/Keras,
    TFLite, scikit-learn, and other frameworks.
  license: MIT AND BSL-1.0
  license_family: MIT
  license_file:
    - LICENSE

extra:
  recipe-maintainers:
    - xhochy
    - janjagusch
    - jtilly
    - cbourjau
