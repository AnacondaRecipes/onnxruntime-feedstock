{% set name = "onnxruntime" %}
{% set version = "1.15.1" %}

package:
  name: {{ name|lower }}{{ suffix }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v{{ version }}.tar.gz
    sha256: 93a9b6f148639938ccbaa48d0f641d8f33312fdfcc69ee9466e11362b43917c4
    patches:
      - never_call_install_python_deps.patch
    #   Workaround for https://github.com/conda-forge/onnxruntime-feedstock/pull/56#issuecomment-1586080419
      - windows_workaround_conflict_onnxruntime_dll_system32.patch  # [win]
      - 16337.patch
    #   Workaround for https://github.com/microsoft/onnxruntime/issues/13225

build:
  number: 0
  skip: True # [ppc64le or s390x]
  ignore_run_exports_from:
    - zlib
  entry_points:
    - onnxruntime_test = onnxruntime.tools.onnxruntime_test:main
  missing_dso_whitelist:     # [win64]
    - '**/api-ms-win-core-path-l1-1-0.dll'     # [win64]

requirements:
  build:
    - python
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - git  # [not win]
    - ninja     # [not win64]
  host:
    - python
    - pip
    - wheel
    - flake8
    - gmock
    - patch    # [unix]
    - m2-patch # [win]
    - libdate
    - packaging
    - python-flatbuffers
    - optional-lite
    - zlib
    - zstd {{ zstd }}
    - numpy {{ numpy }}
    - pybind11
    - setuptools
    - wheel
  run:
    - coloredlogs
    - packaging
    - protobuf
    - python
    - python-flatbuffers
    - sympy
    - zstd
    - {{ pin_compatible('numpy') }}
  run_constrained:
    - onnxruntime <0a0  # [suffix == "-novec"]

test:
  imports:
    - onnxruntime
  commands:
    - pip check
    - onnxruntime_test --help
  requires:
    - pip

about:
  home: https://onnxruntime.ai/
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://onnxruntime.ai/docs/
  summary: cross-platform, high performance ML inferencing and training accelerator
  description: |
    ONNX Runtime is a cross-platform machine-learning model accelerator,
    with a flexible interface to integrate hardware-specific libraries.
    ONNX Runtime can be used with models from PyTorch, Tensorflow/Keras,
    TFLite, scikit-learn, and other frameworks.
  license: MIT AND BSL-1.0
  license_family: MIT
  license_file:
    - LICENSE

extra:
  recipe-maintainers:
    - xhochy
    - janjagusch
    - jtilly
    - cbourjau
