{% set name = "onnxruntime" %}
{% set version = "1.17.1" %}

package:
  name: {{ name|lower }}{{ suffix }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v{{ version }}.tar.gz
    sha256: 88335a1ccbccccb35d5d3aaadee090a9745cf90d97ca87c4a3ac5c4b694b7b17
    patches:
      - patches/never_call_install_python_deps.patch
      # Workaround for https://github.com/conda-forge/onnxruntime-feedstock/pull/56#issuecomment-1586080419
      - patches/windows_workaround_conflict_onnxruntime_dll_system32.patch  # [win]
      - patches/skip_onnx_dependent_tests.patch
      - patches/skip_moe_test.patch                                                # [(ep_variant == "cuda")]
      - patches/skip_custom_op_test_with_cuda.patch                                # [(ep_variant == "cuda")]

build:
  number: 0
  skip: True # [ppc64le or s390x]
  string: gpu_cuda{{ cudatoolkit | replace('.', '') }}py{{ CONDA_PY }}h{{PKG_HASH}}_{{ PKG_BUILDNUM }}  # [(ep_variant == "cuda") and (linux and x86_64)]
  ignore_run_exports_from:
    - zlib
  entry_points:
    - onnxruntime_test = onnxruntime.tools.onnxruntime_test:main
  missing_dso_whitelist:
    - '**/api-ms-win-core-path-l1-1-0.dll'     # [win]
    # CUDA runtime libraries are provided by a platform install for our cuda 11.8
    - "**/libcuda.so*"            # [(ep_variant == "cuda") and (linux and x86_64)]
    - "**/libc10_cuda.so"         # [(ep_variant == "cuda") and (linux and x86_64)]

requirements:
  build:
    - python
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - git  # [not win]
    - ninja     # [not win]
    - patch    # [unix]
    - m2-patch # [win]
  host:
    - python
    - pip
    - wheel
    - flake8
    - gmock
    - libdate
    - packaging
    - python-flatbuffers
    - optional-lite
    - zlib
    - zstd {{ zstd }}
    - numpy {{ numpy }}
    - pybind11
    - setuptools
    - wheel
    # sympy and pytest are required to run tests
    - sympy
    - pytest
    # GPU requirements
    - cudatoolkit {{ cudatoolkit }}*  # [(ep_variant == "cuda") and (linux and x86_64)]
    - cudnn {{ cudnn }}*              # [(ep_variant == "cuda") and (linux and x86_64)]
    - cupti {{ cudatoolkit }}*        # [(ep_variant == "cuda") and (linux and x86_64)]
  run:
    - coloredlogs
    - packaging
    - protobuf
    - python
    - python-flatbuffers
    - sympy
    - zstd
    - {{ pin_compatible('numpy') }}
    # GPU requirements
    - cudatoolkit {{ cudatoolkit }}*  # [(ep_variant == "cuda") and (linux and x86_64)]
    - cupti {{ cudatoolkit }}*        # [(ep_variant == "cuda") and (linux and x86_64)]
  run_constrained:
    - onnxruntime <0a0  # [suffix == "-novec"]

test:
  imports:
    - onnxruntime
  commands:
    - pip check
    - onnxruntime_test --help
  requires:
    - pip

about:
  home: https://onnxruntime.ai/
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://onnxruntime.ai/docs/
  summary: cross-platform, high performance ML inferencing and training accelerator
  description: |
    ONNX Runtime is a cross-platform machine-learning model accelerator,
    with a flexible interface to integrate hardware-specific libraries.
    ONNX Runtime can be used with models from PyTorch, Tensorflow/Keras,
    TFLite, scikit-learn, and other frameworks.
  license: MIT AND BSL-1.0
  license_family: MIT
  license_file:
    - LICENSE

extra:
  recipe-maintainers:
    - xhochy
    - janjagusch
    - jtilly
    - cbourjau
