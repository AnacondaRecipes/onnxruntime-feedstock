{% set name = "onnxruntime" %}
{% set version = "1.15.0" %}

package:
  name: {{ name|lower }}{{ suffix }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v{{ version }}.tar.gz
    sha256: 7752defd687138870974aa391bd5d3d16228ee449f408d11ea3716e8585c73b4

build:
  number: 0
  skip: True # [ppc64le or win]
  ignore_run_exports_from:
    - zlib

requirements:
  build:
    - python
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake
    - git
    - ninja
    - pybind11
    - numpy 1.21.5   # [py<310]
    - numpy   # [py>=310]
  host:
    - python
    - pip
    - wheel
    - flake8
    - gmock
    - libdate
    - packaging
    - python-flatbuffers
    - optional-lite
    - zlib
    - numpy 1.21.5 # [py<310]
    - numpy # [py>=310]
    - pybind11
    - setuptools
    - wheel
  run:
    - coloredlogs
    - packaging
    - protobuf
    - python
    - python-flatbuffers
    - sympy
    - {{ pin_compatible('numpy') }}
  run_constrained:
    - onnxruntime <0a0  # [suffix == "-novec"]

test:
  imports:
    - onnxruntime
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://onnxruntime.ai/
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://onnxruntime.ai/docs/
  summary: cross-platform, high performance ML inferencing and training accelerator
  description: |
    ONNX Runtime is a cross-platform machine-learning model accelerator,
    with a flexible interface to integrate hardware-specific libraries.
    ONNX Runtime can be used with models from PyTorch, Tensorflow/Keras,
    TFLite, scikit-learn, and other frameworks.
  license: MIT AND BSL-1.0
  license_family: MIT
  license_file:
    - LICENSE
    - cmake/external/onnx/LICENSE

extra:
  recipe-maintainers:
    - xhochy
    - janjagusch
    - jtilly
    - cbourjau
